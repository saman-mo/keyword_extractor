num_classes: 8
mlm_weights_dir: "./app/dependencies/model/weights/mlm_wts_all.pt"
pretrained_model_path: 'bert-base-multilingual-cased'
batch_size: 16
vocab_size: 120174
learning_rate: 5e-5
lr_scheduler_patience: 6
lr_scheduler_factor: 0.1
lr_scheduler_gamma: 0.1
lr_scheduler_milestones: [14, 19]
max_grad_norm: 1.00
max_epochs: 20
attention_probs_dropout_prob: 0.1
hidden_dropout_prob: 0.1
classifier_dropout: 0.1
trained_KE_wts: './app/dependencies/model/weights/KeModel_rev.pt'
tokenizer: './app/dependencies/model/tokenizer'
metrics_threshold: 0.50
max_len: 512
cls_wts: "./app/dependencies/model/weights/cls_wts.pt"